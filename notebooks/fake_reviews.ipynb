{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bdecaa",
   "metadata": {},
   "source": [
    "# fake reviews classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a7e95",
   "metadata": {},
   "source": [
    "- logistic regression\n",
    "- support vector classifier\n",
    "- naive bayes\n",
    "- random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "578832e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa139562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60d2bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1996b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I had read some reviews saying that this bra r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I wasn't sure exactly what it would be. It is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40429</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>You can wear the hood by itself, wear it with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40430</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I liked nothing about this dress. The only rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40431</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I work in the wedding industry and have to wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40432 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category  rating label  \\\n",
       "0                Home_and_Kitchen_5     5.0    CG   \n",
       "1                Home_and_Kitchen_5     5.0    CG   \n",
       "2                Home_and_Kitchen_5     5.0    CG   \n",
       "3                Home_and_Kitchen_5     1.0    CG   \n",
       "4                Home_and_Kitchen_5     5.0    CG   \n",
       "...                             ...     ...   ...   \n",
       "40427  Clothing_Shoes_and_Jewelry_5     4.0    OR   \n",
       "40428  Clothing_Shoes_and_Jewelry_5     5.0    CG   \n",
       "40429  Clothing_Shoes_and_Jewelry_5     2.0    OR   \n",
       "40430  Clothing_Shoes_and_Jewelry_5     1.0    CG   \n",
       "40431  Clothing_Shoes_and_Jewelry_5     5.0    OR   \n",
       "\n",
       "                                                   text_  \n",
       "0      Love this!  Well made, sturdy, and very comfor...  \n",
       "1      love it, a great upgrade from the original.  I...  \n",
       "2      This pillow saved my back. I love the look and...  \n",
       "3      Missing information on how to use it, but it i...  \n",
       "4      Very nice set. Good quality. We have had the s...  \n",
       "...                                                  ...  \n",
       "40427  I had read some reviews saying that this bra r...  \n",
       "40428  I wasn't sure exactly what it would be. It is ...  \n",
       "40429  You can wear the hood by itself, wear it with ...  \n",
       "40430  I liked nothing about this dress. The only rea...  \n",
       "40431  I work in the wedding industry and have to wor...  \n",
       "\n",
       "[40432 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. import dataset\n",
    "df = pd.read_csv(\"../data/fake_reviews.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1508d",
   "metadata": {},
   "source": [
    "- Clean the review text (lowercasing; removing punctuation, digits and stop words).\n",
    "- Vectorize review text into numerical vectors (TfidfVectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4239a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing\n",
    "\n",
    "# a) encode label\n",
    "df['encoded_label'] = df['label'].map({'OR': 0, 'CG': 1})\n",
    "\n",
    "\n",
    "# b) Clean the review text\n",
    "from utils.clean_text import clean_text\n",
    "\n",
    "df['clean_text'] = df['text_'].apply(clean_text)\n",
    "\n",
    "\n",
    "# c) Vectorize review text into numerical vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "y = df[\"encoded_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2514add7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>encoded_label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>1</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>1</td>\n",
       "      <td>love great upgrade original ive mine couple years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>1</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>1</td>\n",
       "      <td>missing information use great product price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>1</td>\n",
       "      <td>nice set good quality set two months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I had read some reviews saying that this bra r...</td>\n",
       "      <td>0</td>\n",
       "      <td>read reviews saying bra ran small ordered two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I wasn't sure exactly what it would be. It is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>wasnt sure exactly would little large small si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40429</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>You can wear the hood by itself, wear it with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>wear hood wear hood wear jacket without hood s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40430</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I liked nothing about this dress. The only rea...</td>\n",
       "      <td>1</td>\n",
       "      <td>liked nothing dress reason gave stars ordered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40431</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I work in the wedding industry and have to wor...</td>\n",
       "      <td>0</td>\n",
       "      <td>work wedding industry work long days feet outs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40432 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category  rating label  \\\n",
       "0                Home_and_Kitchen_5     5.0    CG   \n",
       "1                Home_and_Kitchen_5     5.0    CG   \n",
       "2                Home_and_Kitchen_5     5.0    CG   \n",
       "3                Home_and_Kitchen_5     1.0    CG   \n",
       "4                Home_and_Kitchen_5     5.0    CG   \n",
       "...                             ...     ...   ...   \n",
       "40427  Clothing_Shoes_and_Jewelry_5     4.0    OR   \n",
       "40428  Clothing_Shoes_and_Jewelry_5     5.0    CG   \n",
       "40429  Clothing_Shoes_and_Jewelry_5     2.0    OR   \n",
       "40430  Clothing_Shoes_and_Jewelry_5     1.0    CG   \n",
       "40431  Clothing_Shoes_and_Jewelry_5     5.0    OR   \n",
       "\n",
       "                                                   text_  encoded_label  \\\n",
       "0      Love this!  Well made, sturdy, and very comfor...              1   \n",
       "1      love it, a great upgrade from the original.  I...              1   \n",
       "2      This pillow saved my back. I love the look and...              1   \n",
       "3      Missing information on how to use it, but it i...              1   \n",
       "4      Very nice set. Good quality. We have had the s...              1   \n",
       "...                                                  ...            ...   \n",
       "40427  I had read some reviews saying that this bra r...              0   \n",
       "40428  I wasn't sure exactly what it would be. It is ...              1   \n",
       "40429  You can wear the hood by itself, wear it with ...              0   \n",
       "40430  I liked nothing about this dress. The only rea...              1   \n",
       "40431  I work in the wedding industry and have to wor...              0   \n",
       "\n",
       "                                              clean_text  \n",
       "0      love well made sturdy comfortable love itvery ...  \n",
       "1      love great upgrade original ive mine couple years  \n",
       "2                pillow saved back love look feel pillow  \n",
       "3            missing information use great product price  \n",
       "4                   nice set good quality set two months  \n",
       "...                                                  ...  \n",
       "40427  read reviews saying bra ran small ordered two ...  \n",
       "40428  wasnt sure exactly would little large small si...  \n",
       "40429  wear hood wear hood wear jacket without hood s...  \n",
       "40430  liked nothing dress reason gave stars ordered ...  \n",
       "40431  work wedding industry work long days feet outs...  \n",
       "\n",
       "[40432 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. save cleaned dataset\n",
    "df.to_csv(\"../data/cleaned_reviews.csv\", index=False)\n",
    "df = pd.read_csv(\"../data/cleaned_reviews.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c590bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. train test spilt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23d9b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "-> performance metrics for test data\n",
      "- classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      4044\n",
      "           1       0.89      0.88      0.88      4043\n",
      "\n",
      "    accuracy                           0.88      8087\n",
      "   macro avg       0.88      0.88      0.88      8087\n",
      "weighted avg       0.88      0.88      0.88      8087\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "SVM\n",
      "-> performance metrics for test data\n",
      "- classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4044\n",
      "           1       0.88      0.89      0.88      4043\n",
      "\n",
      "    accuracy                           0.88      8087\n",
      "   macro avg       0.88      0.88      0.88      8087\n",
      "weighted avg       0.88      0.88      0.88      8087\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Naive Bayes\n",
      "-> performance metrics for test data\n",
      "- classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      4044\n",
      "           1       0.83      0.88      0.86      4043\n",
      "\n",
      "    accuracy                           0.85      8087\n",
      "   macro avg       0.85      0.85      0.85      8087\n",
      "weighted avg       0.85      0.85      0.85      8087\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Random Forest\n",
      "-> performance metrics for test data\n",
      "- classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      4044\n",
      "           1       0.84      0.88      0.86      4043\n",
      "\n",
      "    accuracy                           0.86      8087\n",
      "   macro avg       0.86      0.86      0.86      8087\n",
      "weighted avg       0.86      0.86      0.86      8087\n",
      "\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. train model -> predict -> performance metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "models={\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": LinearSVC(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "\n",
    "    # a) train model\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # b) predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # c) performance metrics \n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print(\"-> performance metrics for test data\")\n",
    "    # print(\"- Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    # print(\"- F1 score: {:.4f}\".format(f1_score(y_test, y_pred)))\n",
    "    # print(\"- Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "    # print(\"- Recall: {:.4f}\".format(recall_score(y_test, y_pred)))\n",
    "    print(\"- classification report: \\n\", classification_report(y_test, y_pred))\n",
    "    print('----------------------------------')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "682672f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score (5-fold CV): 0.8726\n",
      "SVM F1 Score (5-fold CV): 0.8760\n",
      "Naive Bayes F1 Score (5-fold CV): 0.8583\n",
      "Random Forest F1 Score (5-fold CV): 0.8471\n"
     ]
    }
   ],
   "source": [
    "#  6. cross validation score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    print(f\"{name} F1 Score (5-fold CV): {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff06a463",
   "metadata": {},
   "source": [
    "7. hyperparameter tunning and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb4492e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],           # Inverse of regularization\n",
    "    'penalty': ['l2'],                      # 'l1' is slower and not always supported\n",
    "    'solver': ['liblinear', 'lbfgs'],       # 'liblinear' supports small datasets and l1/l2\n",
    "    'max_iter': [100, 500, 1000, 2000]\n",
    "}\n",
    "svm_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    # 'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "nb_params = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "}\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 500, 1000],  # Number of trees\n",
    "    'max_depth': [5, 10, 15, 20, None],     # Tree depth\n",
    "    'min_samples_split': [2, 5, 10, 20],    # Minimum samples to split\n",
    "    'min_samples_leaf': [1, 2, 4, 8],       # Minimum samples at leaf\n",
    "    'bootstrap': [True, False]              # Bootstrap sampling\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb0df3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "randomcv_models = [\n",
    "        (\"LR\", LogisticRegression(), lr_params),\n",
    "        (\"SVM\", LinearSVC(), svm_params),\n",
    "        # (\"NB\", MultinomialNB(), nb_params),\n",
    "        # (\"RF\", RandomForestClassifier(), rf_params),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d9910eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "LR\n",
      "{'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 10}\n",
      "0.8739526714308138\n",
      "SVM\n",
      "{'max_iter': 1000, 'loss': 'hinge', 'C': 1}\n",
      "0.8732106739878404\n"
     ]
    }
   ],
   "source": [
    "# random search cv\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "model_score = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=params,\n",
    "        n_iter=100,\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "    model_score[name] = random.best_score_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(model_name)\n",
    "    print(model_param[model_name])\n",
    "    print(model_score[model_name])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
